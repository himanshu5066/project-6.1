{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7301369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import logging\n",
    "from datetime import datetime\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9002c0",
   "metadata": {},
   "source": [
    "# Set Up Logging\n",
    "Set up logging to track the progress and save logs to a file with a timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47167bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    filename=f'sales_forecast_{datetime.now().strftime(\"%Y-%m-%d\")}.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger('sales_forecast')\n",
    "logger.info(\"Starting sales forecasting analysis for Rossmann Pharmaceuticals\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c4412",
   "metadata": {},
   "source": [
    "# Load and Explore Data\n",
    "Load the datasets (store.csv, train.csv, test.csv) and display their shapes and first few rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aca2b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store Data Shape: (1115, 10)\n",
      "Train Data Shape: (1017209, 9)\n",
      "Test Data Shape: (41088, 8)\n",
      "\n",
      "Store Data Preview:\n",
      "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
      "0      1         c          a               1270.0                        9.0   \n",
      "1      2         a          a                570.0                       11.0   \n",
      "2      3         a          a              14130.0                       12.0   \n",
      "3      4         c          c                620.0                        9.0   \n",
      "4      5         a          a              29910.0                        4.0   \n",
      "\n",
      "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
      "0                    2008.0       0              NaN              NaN   \n",
      "1                    2007.0       1             13.0           2010.0   \n",
      "2                    2006.0       1             14.0           2011.0   \n",
      "3                    2009.0       0              NaN              NaN   \n",
      "4                    2015.0       0              NaN              NaN   \n",
      "\n",
      "     PromoInterval  \n",
      "0              NaN  \n",
      "1  Jan,Apr,Jul,Oct  \n",
      "2  Jan,Apr,Jul,Oct  \n",
      "3              NaN  \n",
      "4              NaN  \n",
      "\n",
      "Train Data Preview:\n",
      "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
      "0      1          5  2015-07-31   5263        555     1      1            0   \n",
      "1      2          5  2015-07-31   6064        625     1      1            0   \n",
      "2      3          5  2015-07-31   8314        821     1      1            0   \n",
      "3      4          5  2015-07-31  13995       1498     1      1            0   \n",
      "4      5          5  2015-07-31   4822        559     1      1            0   \n",
      "\n",
      "   SchoolHoliday  \n",
      "0              1  \n",
      "1              1  \n",
      "2              1  \n",
      "3              1  \n",
      "4              1  \n",
      "\n",
      "Test Data Preview:\n",
      "   Id  Store  DayOfWeek        Date  Open  Promo StateHoliday  SchoolHoliday\n",
      "0   1      1          4  2015-09-17   1.0      1            0              0\n",
      "1   2      3          4  2015-09-17   1.0      1            0              0\n",
      "2   3      7          4  2015-09-17   1.0      1            0              0\n",
      "3   4      8          4  2015-09-17   1.0      1            0              0\n",
      "4   5      9          4  2015-09-17   1.0      1            0              0\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "logger.info(\"Loading data files\")\n",
    "store_data = pd.read_csv('store.csv')\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Display basic information about the datasets\n",
    "logger.info(\"Displaying basic information about the datasets\")\n",
    "print(\"Store Data Shape:\", store_data.shape)\n",
    "print(\"Train Data Shape:\", train_data.shape)\n",
    "print(\"Test Data Shape:\", test_data.shape)\n",
    "\n",
    "# Display the first few rows of each dataset\n",
    "print(\"\\nStore Data Preview:\")\n",
    "print(store_data.head())\n",
    "\n",
    "print(\"\\nTrain Data Preview:\")\n",
    "print(train_data.head())\n",
    "\n",
    "print(\"\\nTest Data Preview:\")\n",
    "print(test_data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4706271d",
   "metadata": {},
   "source": [
    "# Check for Missing Values\n",
    "Check for missing values in the datasets and log the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56cd5594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values in Store Data:\n",
      "Store                          0\n",
      "StoreType                      0\n",
      "Assortment                     0\n",
      "CompetitionDistance            3\n",
      "CompetitionOpenSinceMonth    354\n",
      "CompetitionOpenSinceYear     354\n",
      "Promo2                         0\n",
      "Promo2SinceWeek              544\n",
      "Promo2SinceYear              544\n",
      "PromoInterval                544\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Train Data:\n",
      "Store            0\n",
      "DayOfWeek        0\n",
      "Date             0\n",
      "Sales            0\n",
      "Customers        0\n",
      "Open             0\n",
      "Promo            0\n",
      "StateHoliday     0\n",
      "SchoolHoliday    0\n",
      "dtype: int64\n",
      "\n",
      "Missing values in Test Data:\n",
      "Id                0\n",
      "Store             0\n",
      "DayOfWeek         0\n",
      "Date              0\n",
      "Open             11\n",
      "Promo             0\n",
      "StateHoliday      0\n",
      "SchoolHoliday     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "logger.info(\"Checking for missing values\")\n",
    "print(\"\\nMissing values in Store Data:\")\n",
    "print(store_data.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in Train Data:\")\n",
    "print(train_data.isnull().sum())\n",
    "\n",
    "print(\"\\nMissing values in Test Data:\")\n",
    "print(test_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14d1fab",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "Merge train and store data, convert date columns, and extract date-related features such as year, month, and day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7ca875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Merged Train and Store Data Shape: (1017209, 18)\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "logger.info(\"Starting data preprocessing\")\n",
    "\n",
    "# Merge train data with store data\n",
    "train_store = pd.merge(train_data, store_data, on='Store', how='left')\n",
    "print(\"\\nMerged Train and Store Data Shape:\", train_store.shape)\n",
    "\n",
    "# Convert Date column to datetime\n",
    "train_store['Date'] = pd.to_datetime(train_store['Date'])\n",
    "\n",
    "# Extract date features\n",
    "logger.info(\"Extracting date features\")\n",
    "train_store['Year'] = train_store['Date'].dt.year\n",
    "train_store['Month'] = train_store['Date'].dt.month\n",
    "train_store['Day'] = train_store['Date'].dt.day\n",
    "train_store['DayOfWeek'] = train_store['Date'].dt.dayofweek\n",
    "train_store['WeekOfYear'] = train_store['Date'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2e171e",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)\n",
    "Perform EDA by plotting sales distribution, average sales by day of the week, and other visualizations to understand the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641079b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA - Exploratory Data Analysis\n",
    "logger.info(\"Starting Exploratory Data Analysis\")\n",
    "\n",
    "# Plot sales distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(train_store['Sales'], kde=True)\n",
    "plt.title('Sales Distribution')\n",
    "plt.xlabel('Sales')\n",
    "plt.ylabel('Frequency')\n",
    "plt.savefig('sales_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Plot average sales by day of week\n",
    "plt.figure(figsize=(10, 6))\n",
    "avg_sales_by_dow = train_store.groupby('DayOfWeek')['Sales'].mean().reset_index()\n",
    "sns.barplot(x='DayOfWeek', y='Sales', data=avg_sales_by_dow)\n",
    "plt.title('Average Sales by Day of Week')\n",
    "plt.xlabel('Day of Week (0=Monday, 6=Sunday)')\n",
    "plt.ylabel('Average Sales')\n",
    "plt.savefig('avg_sales_by_dow.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e682bba3",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "Create new features such as weekend flag, month part categories, and handle missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d141dcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create weekend flag\n",
    "train_store['IsWeekend'] = train_store['DayOfWeek'].apply(lambda x: 1 if x >= 5 else 0)\n",
    "\n",
    "# Create month part categories (beginning, middle, end)\n",
    "train_store['MonthPart'] = train_store['Day'].apply(\n",
    "    lambda x: 'Beginning' if x <= 10 else ('Middle' if x <= 20 else 'End')\n",
    ")\n",
    "\n",
    "# Handle missing values\n",
    "logger.info(\"Handling missing values\")\n",
    "train_store['CompetitionDistance'].fillna(train_store['CompetitionDistance'].max() * 2, inplace=True)\n",
    "train_store['CompetitionOpenSinceMonth'].fillna(train_store['CompetitionOpenSinceMonth'].median(), inplace=True)\n",
    "train_store['CompetitionOpenSinceYear'].fillna(train_store['CompetitionOpenSinceYear'].median(), inplace=True)\n",
    "train_store['Promo2SinceWeek'].fillna(0, inplace=True)\n",
    "train_store['Promo2SinceYear'].fillna(0, inplace=True)\n",
    "train_store['PromoInterval'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66dc821",
   "metadata": {},
   "source": [
    "# Prepare Data for Modeling\n",
    "Convert categorical variables to numeric using one-hot encoding, drop unnecessary columns, and split the data into training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa24cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numeric using one-hot encoding\n",
    "logger.info(\"Converting categorical variables to numeric\")\n",
    "train_store = pd.get_dummies(train_store, columns=['StoreType', 'Assortment', 'StateHoliday', 'MonthPart'])\n",
    "\n",
    "# Drop unnecessary columns\n",
    "train_store.drop(['Date', 'PromoInterval'], axis=1, inplace=True)\n",
    "\n",
    "# Feature selection for model\n",
    "logger.info(\"Selecting features for modeling\")\n",
    "features = train_store.drop(['Sales', 'Customers'], axis=1)\n",
    "target = train_store['Sales']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(features, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90be9d2",
   "metadata": {},
   "source": [
    "# Train Random Forest Model\n",
    "Train a Random Forest Regressor using a pipeline with StandardScaler and evaluate its performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf7f18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train a RandomForestRegressor with a pipeline\n",
    "logger.info(\"Training Random Forest model\")\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on validation set\n",
    "y_pred = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb62968",
   "metadata": {},
   "source": [
    "# Evaluate Model Performance\n",
    "Calculate evaluation metrics such as MAE, RMSE, and R2 score for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e7f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Metrics:\n",
      "Mean Absolute Error (MAE): 486.38\n",
      "Root Mean Squared Error (RMSE): 836.73\n",
      "R2 Score: 0.9527\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "logger.info(\"Evaluating model performance\")\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "print(\"\\nModel Evaluation Metrics:\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "print(f\"R2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57404fd9",
   "metadata": {},
   "source": [
    "# Feature Importance Analysis\n",
    "Analyze and plot the feature importance to understand which features contribute the most to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624a434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Most Important Features:\n",
      "                      Feature  Importance\n",
      "2                        Open    0.459827\n",
      "5         CompetitionDistance    0.105815\n",
      "0                       Store    0.084487\n",
      "3                       Promo    0.073461\n",
      "7    CompetitionOpenSinceYear    0.043970\n",
      "6   CompetitionOpenSinceMonth    0.037660\n",
      "1                   DayOfWeek    0.032290\n",
      "13                        Day    0.023369\n",
      "10            Promo2SinceYear    0.021889\n",
      "14                 WeekOfYear    0.020745\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "rf = pipeline.named_steps['rf']\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features.columns,\n",
    "    'Importance': rf.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Most Important Features:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance.head(15))\n",
    "plt.title('Feature Importance')\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importance.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1747b7",
   "metadata": {},
   "source": [
    "# Save the Trained Model\n",
    "Serialize the trained model using pickle and save it with a timestamped filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ad4645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved as rf_model_28-04-2025-10-53-15-922500.pkl\n"
     ]
    }
   ],
   "source": [
    "# Serialize the model with timestamp\n",
    "logger.info(\"Serializing the model\")\n",
    "timestamp = datetime.now().strftime(\"%d-%m-%Y-%H-%M-%S-%f\")\n",
    "model_filename = f'rf_model_{timestamp}.pkl'\n",
    "\n",
    "with open(model_filename, 'wb') as file:\n",
    "    pickle.dump(pipeline, file)\n",
    "\n",
    "print(f\"\\nModel saved as {model_filename}\")\n",
    "logger.info(f\"Analysis completed. Model saved as {model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
